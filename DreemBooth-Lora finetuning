{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12010504,"sourceType":"datasetVersion","datasetId":7553700}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall datasets -y\n!pip uninstall fastai -y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install fsspec==2025.3.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir \\\n    torch==2.7.0 \\\n    torchvision==0.22.0 \\\n    torchaudio==2.7.0 \\\n    --index-url https://download.pytorch.org/whl/cu126 -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir \\\n    huggingface_hub>=0.18.0 \\\n    diffusers==0.27.2 \\\n    peft==0.14.0 \\\n    accelerate==0.27.2 \\\n    safetensors \\\n    xformers==0.0.30 \\\n    timm==1.0.15 -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport subprocess\nimport sys\nimport time\nimport gc\n\nprint(\"Step 3: Clone Diffusers repository (if not already present).\")\nif not os.path.exists('diffusers'):\n    !git clone https://github.com/huggingface/diffusers.git\nelse:\n    print(\"Diffusers repository already cloned.\")\n\nprint(\"\\n--- Dependency Setup Completed. Verifying Environment. ---\")\n\n# --- Rest of your code (paste it here, unchanged, from your previous notebook) ---\n\n# Define your constants again, ensuring they are accessible\nDREAMBOOTH_SCRIPT = './diffusers/examples/dreambooth/train_dreambooth_lora.py'\nCHARACTER_ROOT = '/kaggle/input/cartoon-characters-new/'\nOUTPUT_ROOT = '/kaggle/working/dreambooth_models/'\nPRETRAINED_MODEL = 'CompVis/stable-diffusion-v1-4'\n\n# Your existing functions\ndef check_xformers_availability():\n    try:\n        import xformers\n        print(f\"‚úÖ xformers available: {xformers.__version__}\")\n        return True\n    except ImportError:\n        print(\"‚ö†Ô∏è xformers not available - will use standard attention\")\n        return False\n\ndef debug_environment():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ENVIRONMENT DEBUG\")\n    print(\"=\"*60)\n    print(f\"Python: {sys.version}\")\n    try:\n        import torch\n        print(f\"PyTorch: {torch.__version__}\")\n        print(f\"CUDA available: {torch.cuda.is_available()}\")\n        if torch.cuda.is_available():\n            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n            print(f\"GPU Memory Available: {torch.cuda.memory_allocated(0) / 1e9:.1f} GB used\")\n    except Exception as e:\n        print(f\"GPU check failed: {e}\")\n    \n    deps = ['diffusers', 'transformers', 'accelerate', 'peft', 'torchvision', 'xformers', 'timm', 'huggingface_hub'] # Added huggingface_hub\n    for dep in deps:\n        try:\n            module = __import__(dep)\n            version = getattr(module, '__version__', 'Unknown')\n            print(f\"{dep}: {version}\")\n        except ImportError:\n            print(f\"{dep}: NOT INSTALLED\")\n    \n    xformers_available = check_xformers_availability()\n    \n    print(f\"\\nTraining script: {DREAMBOOTH_SCRIPT}\")\n    print(f\"Exists: {os.path.exists(DREAMBOOTH_SCRIPT)}\")\n    \n    if os.path.exists(DREAMBOOTH_SCRIPT):\n        try:\n            result = subprocess.run([\n                sys.executable, DREAMBOOTH_SCRIPT, '--help'\n            ], capture_output=True, text=True, timeout=30)\n            \n            if result.returncode == 0:\n                print(\"‚úÖ Training script accessible\")\n            else:\n                print(\"‚ùå Training script error:\")\n                print(f\"STDOUT: {result.stdout[:300]}\")\n                print(f\"STDERR: {result.stderr[:300]}\")\n        except Exception as e:\n            print(f\"Script test failed: {e}\")\n    \n    try:\n        result = subprocess.run(['accelerate', 'env'], capture_output=True, text=True, timeout=10)\n        print(f\"\\nAccelerate env check - Return code: {result.returncode}\")\n        if result.stdout:\n            print(\"Accelerate config:\")\n            print(result.stdout[:500])\n        if result.stderr:\n            print(\"Accelerate errors:\")\n            print(result.stderr[:500])\n    except Exception as e:\n        print(f\"Accelerate check failed: {e}\")\n    \n    print(\"=\"*60)\n    return xformers_available\n\ndef get_valid_characters():\n    if not os.path.exists(CHARACTER_ROOT):\n        return []\n    valid_chars = []\n    for folder in os.listdir(CHARACTER_ROOT):\n        folder_path = os.path.join(CHARACTER_ROOT, folder)\n        if not os.path.isdir(folder_path):\n            continue\n        image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}\n        has_images = False\n        image_count = 0\n        for file in os.listdir(folder_path):\n            if any(file.lower().endswith(ext) for ext in image_exts):\n                has_images = True\n                image_count += 1\n        if has_images:\n            print(f\"Found character '{folder}' with {image_count} images\")\n            valid_chars.append(folder)\n        else:\n            print(f\"Skipping '{folder}' - no images found\")\n    return valid_chars\n\ndef set_cuda_memory_optimization():\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n    try:\n        import torch\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            torch.backends.cudnn.benchmark = False\n            torch.backends.cudnn.deterministic = True\n            print(\"‚úÖ CUDA memory optimizations applied\")\n    except Exception as e:\n        print(f\"Warning: Could not apply CUDA optimizations: {e}\")\n\ndef create_base_training_command(instance_dir, output_dir, instance_prompt, use_xformers=False):\n    command = [\n        'accelerate', 'launch',\n        '--mixed_precision=fp16',\n        DREAMBOOTH_SCRIPT,\n        '--pretrained_model_name_or_path', PRETRAINED_MODEL,\n        '--instance_data_dir', instance_dir,\n        '--output_dir', output_dir,\n        '--instance_prompt', instance_prompt,\n        '--resolution', '512',\n        '--train_batch_size', '1',\n        '--gradient_accumulation_steps', '1',\n        '--learning_rate', '1e-4',\n        '--lr_scheduler', 'constant',\n        '--lr_warmup_steps', '0',\n        '--max_train_steps', '800',\n        '--validation_epochs', '50',\n        '--seed', '1337',\n        '--mixed_precision', 'fp16',\n        '--gradient_checkpointing',\n        '--use_8bit_adam',\n        '--enable_xformers_memory_efficient_attention',\n        '--dataloader_num_workers', '0',\n        '--validation_prompt', 'A photo of a person',\n        '--report_to', 'tensorboard',\n        '--logging_dir', os.path.join(output_dir, 'logs'),\n        '--train_text_encoder',\n        '--use_lora',\n        '--lora_r', '16',\n        '--lora_alpha', '32',\n        '--lora_bias', 'none',\n        '--lora_dropout', '0.1',\n    ]\n    return command\n\ndef run_training_with_fallback_strategies(character, instance_dir, output_dir, instance_prompt, use_xformers=False):\n    set_cuda_memory_optimization()\n    \n    print(\"üöÄ Strategy 1: Full optimization (8-bit Adam + text encoder)\")\n    command = create_base_training_command(instance_dir, output_dir, instance_prompt, use_xformers)\n    command.extend([\n        '--use_8bit_adam',\n        '--train_text_encoder',\n    ])\n    \n    success, message = run_training_command(command, character, \"Strategy 1\")\n    if success:\n        return success, message\n    \n    if \"out of memory\" in message.lower() or \"cuda\" in message.lower():\n        print(\"üöÄ Strategy 2: Remove text encoder training\")\n        command = create_base_training_command(instance_dir, output_dir, instance_prompt, use_xformers)\n        command.append('--use_8bit_adam')\n        \n        success, message = run_training_command(command, character, \"Strategy 2\")\n        if success:\n            return success, message\n    \n    if \"out of memory\" in message.lower() or \"cuda\" in message.lower():\n        print(\"üöÄ Strategy 3: Standard Adam optimizer\")\n        command = create_base_training_command(instance_dir, output_dir, instance_prompt, use_xformers)\n        \n        success, message = run_training_command(command, character, \"Strategy 3\")\n        if success:\n            return success, message\n    \n    if \"out of memory\" in message.lower() or \"cuda\" in message.lower():\n        print(\"üöÄ Strategy 4: Ultra-minimal (256x256, reduced steps)\")\n        command = create_base_training_command(instance_dir, output_dir, instance_prompt, False)\n        \n        for i, arg in enumerate(command):\n            if arg == '--resolution':\n                command[i+1] = '256'\n            elif arg == '--max_train_steps':\n                command[i+1] = '200'\n            elif arg == '--checkpointing_steps':\n                command[i+1] = '200'\n            elif arg == '--validation_steps':\n                command[i+1] = '200'\n        \n        success, message = run_training_command(command, character, \"Strategy 4\")\n        if success:\n            return success, message\n    \n    if \"out of memory\" in message.lower() or \"cuda\" in message.lower():\n        print(\"üöÄ Strategy 5: Smaller base model (CompVis/stable-diffusion-v1-4)\")\n        command = create_base_training_command(instance_dir, output_dir, instance_prompt, False)\n        \n        for i, arg in enumerate(command):\n            if arg == 'runwayml/stable-diffusion-v1-5':\n                command[i] = 'CompVis/stable-diffusion-v1-4'\n            elif arg == '--resolution':\n                command[i+1] = '256'\n            elif arg == '--max_train_steps':\n                command[i+1] = '200'\n            elif arg == '--checkpointing_steps':\n                command[i+1] = '200'\n            elif arg == '--validation_steps':\n                command[i+1] = '200'\n    \n    success, message = run_training_command(command, character, \"Strategy 5\")\n    return success, message\n\ndef run_training_command(command, character, strategy_name):\n    print(f\"Command for {strategy_name}:\")\n    print(' '.join(command))\n    \n    try:\n        import torch\n        if torch.cuda.is_available():\n            for _ in range(3):\n                torch.cuda.empty_cache()\n                torch.cuda.synchronize()\n                gc.collect()\n                time.sleep(0.2)\n            memory_allocated = torch.cuda.memory_allocated(0) / 1e9\n            memory_reserved = torch.cuda.memory_reserved(0) / 1e9\n            print(f\"Before training - Allocated: {memory_allocated:.1f} GB, Reserved: {memory_reserved:.1f} GB\")\n    except Exception as e:\n        print(f\"Memory clearing warning: {e}\")\n    \n    print(f\"Starting {strategy_name} for '{character}'...\")\n    process = subprocess.Popen(\n        command,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        bufsize=1,\n        universal_newlines=True,\n        env=dict(os.environ, PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True')\n    )\n    \n    output_lines = []\n    start_time = time.time()\n    \n    try:\n        while True:\n            output = process.stdout.readline()\n            if output == '' and process.poll() is not None:\n                break\n            if output:\n                line = output.strip()\n                print(f\"    {line}\")\n                output_lines.append(line)\n                \n                if 'step' in line.lower() and ('loss' in line.lower() or 'lr' in line.lower()):\n                    elapsed = time.time() - start_time\n                    print(f\"    [Elapsed: {elapsed/60:.1f}m]\")\n                \n                if \"out of memory\" in line.lower() or \"cuda out of memory\" in line.lower():\n                    print(f\"    üí• Memory error detected, terminating...\")\n                    process.terminate()\n                    break\n                    \n                if \"xformers is not available\" in line.lower():\n                    print(f\"    üí• xformers error detected, terminating...\")\n                    process.terminate()\n                    break\n    \n        return_code = process.poll()\n        full_output = '\\n'.join(output_lines)\n        \n        if return_code == 0:\n            print(f\"‚úÖ Successfully trained '{character}' with {strategy_name}\")\n            return True, \"Success\"\n        else:\n            print(f\"‚ùå {strategy_name} failed with return code: {return_code}\")\n            \n            if output_lines:\n                print(\"Last 3 output lines:\")\n                for line in output_lines[-3:]:\n                    print(f\"    {line}\")\n            \n            return False, f\"Return code {return_code}: {full_output[-500:]}\"\n    \n    except Exception as e:\n        print(f\"‚ùå {strategy_name} exception: {e}\")\n        return False, str(e)\n\ndef main():\n    print(\"üöÄ Starting Memory-Optimized DreamBooth Training for Kaggle P100\")\n    print(\"=\"*60)\n    \n    xformers_available = debug_environment()\n    \n    if not os.path.exists(DREAMBOOTH_SCRIPT):\n        print(f\"‚ùå Training script not found: {DREAMBOOTH_SCRIPT}\")\n        return\n    \n    if not os.path.exists(CHARACTER_ROOT):\n        print(f\"‚ùå Character directory not found: {CHARACTER_ROOT}\")\n        return\n    \n    os.makedirs(OUTPUT_ROOT, exist_ok=True)\n    print(f\"üìÅ Output directory: {OUTPUT_ROOT}\")\n    \n    characters = get_valid_characters()\n    if not characters:\n        print(\"‚ùå No valid character folders found\")\n        return\n    \n    print(f\"üìä Found {len(characters)} characters to train: {characters}\")\n    \n    results = {'success': [], 'failed': []}\n    \n    for i, character in enumerate(characters, 1):\n        print(f\"\\n{'='*60}\")\n        print(f\"üé≠ TRAINING {i}/{len(characters)}: {character.upper()}\")\n        print(f\"{'='*60}\")\n        \n        instance_dir = os.path.join(CHARACTER_ROOT, character)\n        output_dir = os.path.join(OUTPUT_ROOT, character)\n        os.makedirs(output_dir, exist_ok=True)\n        \n        trigger_word = character.lower().replace(' ', '_').replace('-', '_')\n        instance_prompt = f'a photo of a {trigger_word} person'\n        \n        print(f\"üìÅ Input: {instance_dir}\")\n        print(f\"üìÅ Output: {output_dir}\")\n        print(f\"üí¨ Prompt: '{instance_prompt}'\")\n        print(f\"üîß xformers available: {xformers_available}\")\n        \n        success, message = run_training_with_fallback_strategies(\n            character, instance_dir, output_dir, instance_prompt, xformers_available\n        )\n        \n        if success:\n            results['success'].append(character)\n            print(f\"‚úÖ {character} completed successfully!\")\n        else:\n            results['failed'].append((character, message))\n            print(f\"‚ùå {character} failed: {message[:100]}...\")\n        \n        try:\n            import torch\n            if torch.cuda.is_available():\n                for _ in range(5):\n                    torch.cuda.empty_cache()\n                    torch.cuda.synchronize()\n                    gc.collect()\n                    time.sleep(0.1)\n                print(\"üßπ Post-training memory cleanup completed\")\n        except:\n            pass\n    \n    print(f\"\\n{'='*60}\")\n    print(\"üéØ FINAL RESULTS\")\n    print(f\"{'='*60}\")\n    print(f\"‚úÖ Successful: {len(results['success'])}\")\n    print(f\"‚ùå Failed: {len(results['failed'])}\")\n    \n    if results['success']:\n        print(f\"\\nüéâ Successfully trained:\")\n        for char in results['success']:\n            print(f\"    - {char}\")\n    \n    if results['failed']:\n        print(f\"\\nüí• Failed to train:\")\n        for char, error in results['failed']:\n            print(f\"    - {char}: {error[:80]}...\")\n    \n    if results['success']:\n        print(f\"\\nüéä Models saved in: {OUTPUT_ROOT}\")\n        print(\"You can now use these models for inference!\")\n    else:\n        print(f\"\\nüí° ADDITIONAL TROUBLESHOOTING:\")\n        print(\"    - All fallback strategies failed\")\n        if not xformers_available:\n            print(\"    - Consider installing xformers: pip install xformers\")\n        print(\"    - Your P100 may need even smaller batches or resolution\")\n        print(\"    - Try using LoRA instead of full DreamBooth fine-tuning\")\n        print(\"    - Consider cloud services with more GPU memory\")\n    \n    print(\"=\"*60)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T01:09:04.879189Z","iopub.execute_input":"2025-05-31T01:09:04.879466Z"}},"outputs":[{"name":"stdout","text":"Step 3: Clone Diffusers repository (if not already present).\nCloning into 'diffusers'...\nremote: Enumerating objects: 93500, done.\u001b[K\nremote: Counting objects: 100% (213/213), done.\u001b[K\nremote: Compressing objects: 100% (163/163), done.\u001b[K\nremote: Total 93500 (delta 148), reused 50 (delta 50), pack-reused 93287 (from 4)\u001b[K\nReceiving objects: 100% (93500/93500), 69.70 MiB | 18.20 MiB/s, done.\nResolving deltas: 100% (68909/68909), done.\n\n--- Dependency Setup Completed. Verifying Environment. ---\nüöÄ Starting Memory-Optimized DreamBooth Training for Kaggle P100\n============================================================\n\n============================================================\nENVIRONMENT DEBUG\n============================================================\nPython: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\nPyTorch: 2.7.0+cu126\nCUDA available: True\nGPU: Tesla P100-PCIE-16GB\nGPU Memory: 17.1 GB\nGPU Memory Available: 0.0 GB used\ndiffusers: NOT INSTALLED\ntransformers: 4.51.3\naccelerate: 0.27.2\n","output_type":"stream"},{"name":"stderr","text":"2025-05-31 01:09:23.320004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748653763.526773     132 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748653763.582090     132 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"peft: 0.14.0\ntorchvision: 0.22.0+cu126\nxformers: 0.0.30\ntimm: 1.0.15\nhuggingface_hub: 0.32.3\n‚úÖ xformers available: 0.0.30\n\nTraining script: ./diffusers/examples/dreambooth/train_dreambooth_lora.py\nExists: True\n‚ùå Training script error:\nSTDOUT: \nSTDERR: 2025-05-31 01:09:44.579221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE00\n\nAccelerate env check - Return code: 0\nAccelerate config:\n\nCopy-and-paste the text below in your GitHub issue\n\n- `Accelerate` version: 0.27.2\n- Platform: Linux-6.6.56+-x86_64-with-glibc2.35\n- Python version: 3.11.11\n- Numpy version: 1.26.4\n- PyTorch version (GPU?): 2.7.0+cu126 (True)\n- PyTorch XPU available: False\n- PyTorch NPU available: False\n- System RAM: 31.35 GB\n- GPU type: Tesla P100-PCIE-16GB\n- `Accelerate` default config:\n\tNot found\n\n============================================================\nüìÅ Output directory: /kaggle/working/dreambooth_models/\nFound character 'man' with 26 images\nFound character 'lady' with 9 images\nüìä Found 2 characters to train: ['man', 'lady']\n\n============================================================\nüé≠ TRAINING 1/2: MAN\n============================================================\nüìÅ Input: /kaggle/input/cartoon-characters-new/man\nüìÅ Output: /kaggle/working/dreambooth_models/man\nüí¨ Prompt: 'a photo of a man person'\nüîß xformers available: True\n‚úÖ CUDA memory optimizations applied\nüöÄ Strategy 1: Full optimization (8-bit Adam + text encoder)\nCommand for Strategy 1:\naccelerate launch --mixed_precision=fp16 ./diffusers/examples/dreambooth/train_dreambooth_lora.py --pretrained_model_name_or_path CompVis/stable-diffusion-v1-4 --instance_data_dir /kaggle/input/cartoon-characters-new/man --output_dir /kaggle/working/dreambooth_models/man --instance_prompt a photo of a man person --resolution 512 --train_batch_size 1 --gradient_accumulation_steps 1 --learning_rate 1e-4 --lr_scheduler constant --lr_warmup_steps 0 --max_train_steps 800 --validation_epochs 50 --seed 1337 --mixed_precision fp16 --gradient_checkpointing --use_8bit_adam --enable_xformers_memory_efficient_attention --dataloader_num_workers 0 --validation_prompt A photo of a person --report_to tensorboard --logging_dir /kaggle/working/dreambooth_models/man/logs --train_text_encoder --use_lora --lora_r 16 --lora_alpha 32 --lora_bias none --lora_dropout 0.1 --use_8bit_adam --train_text_encoder\nBefore training - Allocated: 0.0 GB, Reserved: 0.0 GB\nStarting Strategy 1 for 'man'...\n    2025-05-31 01:10:10.217928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n    WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n    E0000 00:00:1748653810.239769     196 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n    E0000 00:00:1748653810.246370     196 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n    Traceback (most recent call last):\n    File \"/kaggle/working/./diffusers/examples/dreambooth/train_dreambooth_lora.py\", line 46, in <module>\n    import diffusers\n    File \"/usr/local/lib/python3.11/dist-packages/diffusers/__init__.py\", line 5, in <module>\n    from .utils import (\n    File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/__init__.py\", line 38, in <module>\n    from .dynamic_modules_utils import get_class_from_dynamic_module\n    File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/dynamic_modules_utils.py\", line 28, in <module>\n    from huggingface_hub import cached_download, hf_hub_download, model_info\n    ImportError: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)\n    Traceback (most recent call last):\n    File \"/usr/local/bin/accelerate\", line 8, in <module>\n    sys.exit(main())\n    ^^^^^^\n    File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n    args.func(args)\n    File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1023, in launch_command\n    simple_launcher(args)\n    File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 643, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n    subprocess.CalledProcessError: Command '['/usr/bin/python3', './diffusers/examples/dreambooth/train_dreambooth_lora.py', '--pretrained_model_name_or_path', 'CompVis/stable-diffusion-v1-4', '--instance_data_dir', '/kaggle/input/cartoon-characters-new/man', '--output_dir', '/kaggle/working/dreambooth_models/man', '--instance_prompt', 'a photo of a man person', '--resolution', '512', '--train_batch_size', '1', '--gradient_accumulation_steps', '1', '--learning_rate', '1e-4', '--lr_scheduler', 'constant', '--lr_warmup_steps', '0', '--max_train_steps', '800', '--validation_epochs', '50', '--seed', '1337', '--mixed_precision', 'fp16', '--gradient_checkpointing', '--use_8bit_adam', '--enable_xformers_memory_efficient_attention', '--dataloader_num_workers', '0', '--validation_prompt', 'A photo of a person', '--report_to', 'tensorboard', '--logging_dir', '/kaggle/working/dreambooth_models/man/logs', '--train_text_encoder', '--use_lora', '--lora_r', '16', '--lora_alpha', '32', '--lora_bias', 'none', '--lora_dropout', '0.1', '--use_8bit_adam', '--train_text_encoder']' returned non-zero exit status 1.\n    [Elapsed: 0.3m]\n‚ùå Strategy 1 failed with return code: 1\nLast 3 output lines:\n    File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 643, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n    subprocess.CalledProcessError: Command '['/usr/bin/python3', './diffusers/examples/dreambooth/train_dreambooth_lora.py', '--pretrained_model_name_or_path', 'CompVis/stable-diffusion-v1-4', '--instance_data_dir', '/kaggle/input/cartoon-characters-new/man', '--output_dir', '/kaggle/working/dreambooth_models/man', '--instance_prompt', 'a photo of a man person', '--resolution', '512', '--train_batch_size', '1', '--gradient_accumulation_steps', '1', '--learning_rate', '1e-4', '--lr_scheduler', 'constant', '--lr_warmup_steps', '0', '--max_train_steps', '800', '--validation_epochs', '50', '--seed', '1337', '--mixed_precision', 'fp16', '--gradient_checkpointing', '--use_8bit_adam', '--enable_xformers_memory_efficient_attention', '--dataloader_num_workers', '0', '--validation_prompt', 'A photo of a person', '--report_to', 'tensorboard', '--logging_dir', '/kaggle/working/dreambooth_models/man/logs', '--train_text_encoder', '--use_lora', '--lora_r', '16', '--lora_alpha', '32', '--lora_bias', 'none', '--lora_dropout', '0.1', '--use_8bit_adam', '--train_text_encoder']' returned non-zero exit status 1.\nCommand for Strategy 5:\naccelerate launch --mixed_precision=fp16 ./diffusers/examples/dreambooth/train_dreambooth_lora.py --pretrained_model_name_or_path CompVis/stable-diffusion-v1-4 --instance_data_dir /kaggle/input/cartoon-characters-new/man --output_dir /kaggle/working/dreambooth_models/man --instance_prompt a photo of a man person --resolution 512 --train_batch_size 1 --gradient_accumulation_steps 1 --learning_rate 1e-4 --lr_scheduler constant --lr_warmup_steps 0 --max_train_steps 800 --validation_epochs 50 --seed 1337 --mixed_precision fp16 --gradient_checkpointing --use_8bit_adam --enable_xformers_memory_efficient_attention --dataloader_num_workers 0 --validation_prompt A photo of a person --report_to tensorboard --logging_dir /kaggle/working/dreambooth_models/man/logs --train_text_encoder --use_lora --lora_r 16 --lora_alpha 32 --lora_bias none --lora_dropout 0.1 --use_8bit_adam --train_text_encoder\nBefore training - Allocated: 0.0 GB, Reserved: 0.0 GB\nStarting Strategy 5 for 'man'...\n","output_type":"stream"}],"execution_count":null}]}